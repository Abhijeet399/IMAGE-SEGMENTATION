{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n",
      "DONE ALL\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.VERSION)\n",
    "#import tensorflow.contib.slim\n",
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "from mxnet import gluon, image, nd\n",
    "from mxnet.gluon import data as gdata, utils as gutils\n",
    "import d2l\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from tensorflow.python.framework import ops\n",
    "import mxnet\n",
    "print(\"DONE ALL\")\n",
    "\n",
    "voc_dir = \"C:\\\\Users\\\\bhatt\\\\Desktop\\\\Jupyter Notebook\\\\VOCdevkit\\\\VOC2012\"\n",
    "\n",
    "def read_voc_images(root=voc_dir, is_train=True):\n",
    "    txt_fname = '%s/ImageSets/Segmentation/%s' % (\n",
    "        root, 'train.txt' if is_train else 'val.txt')\n",
    "    with open(txt_fname, 'r') as f:\n",
    "        images = f.read().split()\n",
    "    features, labels = [None] * len(images), [None] * len(images)\n",
    "    for i, fname in enumerate(images):\n",
    "        features[i] = image.imread('%s/JPEGImages/%s.jpg' % (root, fname))\n",
    "        labels[i] = image.imread(\n",
    "            '%s/SegmentationClass/%s.png' % (root, fname))\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "#train_features, train_labels = read_voc_images()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "from mxnet import gluon, image, nd\n",
    "from mxnet.gluon import data as gdata, utils as gutils\n",
    "import d2l\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import mxnet\n",
    "\n",
    "voc_dir_features = \"C:\\\\Users\\\\bhatt\\\\Desktop\\\\Jupyter Notebook\\\\VOCdevkit\\\\VOC2012\\\\\"\n",
    "voc_dir_labels = \"C:\\\\Users\\\\bhatt\\\\Desktop\\\\Jupyter Notebook\\\\VOCdevkit\\\\VOC2012\\\\\"\n",
    "\n",
    "def read_voc_images(root=voc_dir, is_train=True):\n",
    "    txt_fname = '%s/ImageSets/Segmentation/%s' % (\n",
    "        root, 'train.txt' if is_train else 'val.txt')\n",
    "    with open(txt_fname, 'r') as f:\n",
    "        images = f.read().split()\n",
    "    features, labels = [None] * len(images), [None] * len(images)\n",
    "    total_features=0\n",
    "    for i, fname in enumerate(images):\n",
    "        labels[i] =  cv2.imread(os.path.join(voc_dir_labels,'%s/SegmentationClass/%s.jpg' % (root, fname)))\n",
    "        features[i] = cv2.imread(os.path.join(voc_dir_features,'%s/JPEGImages/%s.jpg' % (root, fname))) \n",
    "        if ((np.ndim(features[i]))>2) and ((np.ndim(labels[i]))>2):\n",
    "            features[i] = cv2.imread(os.path.join(voc_dir_features,'%s/JPEGImages/%s.jpg' % (root, fname))) \n",
    "            labels[i] =  cv2.imread(os.path.join(voc_dir_labels,'%s/SegmentationClass/%s.jpg' % (root, fname)))\n",
    "            total_features = total_features + i\n",
    "        else:  # in the interest in keeping the output clean...\n",
    "            pass\n",
    "    for i in range(20):\n",
    "        print(i)\n",
    "        print(np.ndim(features[i]))\n",
    "        print(features[i].shape)\n",
    "        print(np.ndim(labels[i]))\n",
    "        print(labels[i].shape)\n",
    "    print(total_features)\n",
    "    print(len(features))\n",
    "    print(len(labels))\n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = read_voc_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "imgs = train_features[1424+n:1444+n] + train_labels[1424+n:1444+n]\n",
    "img = train_features[1000] + train_labels[1000]\n",
    "\n",
    "d2l.show_images(imgs, 2, n);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(features,labels):\n",
    "    feature=[]\n",
    "    label=[]\n",
    "    for i in range(1464):\n",
    "        print(i)\n",
    "        feature[i] = features[i].resize((width, height), Image.BICUBIC)  \n",
    "        label[i] = labels[i].resize((width, height), Image.BICUBIC)  \n",
    "        print(i)\n",
    "    return features,labels\n",
    "\n",
    "train_features, train_labels = resize(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(features,labels):\n",
    "    feature=[]\n",
    "    label=[]\n",
    "    for i in range(1464):\n",
    "        print(i)\n",
    "        feature.append(cv2.resize(cv2.UMat(np.array(features[i]), dtype = np.float32),(512,512)))\n",
    "        #label.append(cv2.resize(cv2.UMat(np.array(labels[i]), dtype = np.float32),(512,512)))\n",
    "        #feature.append(features[i])\n",
    "        print(i)\n",
    "    return features,labels\n",
    "\n",
    "train_features, train_labels = resize(train_features, train_labels)\n",
    "#n = 20\n",
    "#imgs = train_features[1424+n:1444+n] + train_labels[1424+n:1444+n]\n",
    "#img = train_features[1000] + train_labels[1000]\n",
    "\n",
    "#d2l.show_images(imgs, 2, n);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_fname = 'C:\\\\Users\\\\bhatt\\\\Desktop\\\\Jupyter Notebook\\\\VOCdevkit\\\\VOC2012\\\\ImageSets\\\\Segmentation\\\\train.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(txt_fname, 'r') as f:\n",
    "        images = f.read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1464"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label =  cv2.imread('C:\\\\Users\\\\bhatt\\\\Desktop\\\\Jupyter Notebook\\\\VOCdevkit\\\\VOC2012\\\\SegmentationClass\\\\' + images[0] + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(281, 500, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "features = []\n",
    "for i in range(len(images)):\n",
    "    print(i)\n",
    "    labels.append(cv2.resize(cv2.imread('C:\\\\Users\\\\bhatt\\\\Desktop\\\\Jupyter Notebook\\\\VOCdevkit\\\\VOC2012\\\\SegmentationClass\\\\' + images[i] + '.png'), (512, 512)))\n",
    "    features.append(cv2.resize(cv2.imread('C:\\\\Users\\\\bhatt\\\\Desktop\\\\Jupyter Notebook\\\\VOCdevkit\\\\VOC2012\\\\JPEGImages\\\\' + images[i] + '.jpg'), (512, 512)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(features[55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(labels[55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(features[316])\n",
    "np.shape(labels[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(labels[316])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_H0, n_W0, n_C0, n_H1,n_W1,n_C1):\n",
    "\n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_H0, n_W0, n_C0])\n",
    "    Y = tf.placeholder(tf.float32, shape=[None, n_H1,n_W1,n_C1])    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    " \n",
    "    tf.set_random_seed(1)                              # so that your \"random\" numbers match ours  \n",
    "    W1 = tf.get_variable(\"W1\", [6, 6, 3, 60], initializer =  tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W2 = tf.get_variable(\"W2\", [3, 3, 60, 25], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W3 = tf.get_variable(\"W3\", [2, 2, 25, 3], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W4 = tf.get_variable(\"W4\", [2, 2, 3, 3], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W5 = tf.get_variable(\"W5\", [6, 6, 3, 3], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W6 = tf.get_variable(\"W6\", [6, 6, 3, 3], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"W2\": W2,\n",
    "                  \"W3\": W3,\n",
    "                  \"W4\": W4,\n",
    "                  \"W5\": W5,\n",
    "                  \"W6\": W6\n",
    "                 }\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "     \n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    W3 = parameters['W3']\n",
    "    W4 = parameters['W4']\n",
    "    W6 = parameters['W6']\n",
    "    W5 = parameters['W5']\n",
    "    # CONV2D: \n",
    "    Z1 = tf.nn.conv2d(X,W1, strides = [1,1,1,1], padding = 'VALID')\n",
    "    # RELU\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    # MAXPOOL:\n",
    "    P1 = tf.nn.max_pool(A1, ksize = [1,3,3,1], strides = [1,2,2,1], padding = 'VALID')\n",
    "    # CONV2D:\n",
    "    Z2 = tf.nn.conv2d(P1,W2, strides = [1,2,2,1], padding = 'VALID')\n",
    "    # RELU\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    # MAXPOOL:\n",
    "    P2 = tf.nn.max_pool(A2, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'VALID')\n",
    "    # FLATTEN\n",
    "    Z3 = tf.nn.conv2d(P2,W3, strides = [1,2,2,1], padding = 'SAME')\n",
    "    # RELU\n",
    "    A3 = tf.nn.relu(Z3)\n",
    "    print(np.shape(A3))\n",
    "    Z4 = tf.contrib.slim.conv2d_transpose(A3,42, kernel_size = [3,3], stride=[2,2],activation_fn=tf.nn.relu)\n",
    "    print(\"A4\")\n",
    "    A4 = tf.nn.relu(Z4)\n",
    "    print(np.shape(A4))\n",
    "    Z6 = tf.contrib.slim.conv2d_transpose(A4,8,[258,258],[2,2],activation_fn=tf.nn.relu)\n",
    "    A6 = tf.nn.relu(Z6)\n",
    "    print(\"A6\")\n",
    "    print(np.shape(A6))\n",
    "    Z7 = tf.contrib.slim.conv2d_transpose(A6,8,[258,258],[2,2],activation_fn=tf.nn.relu)\n",
    "    A7 = tf.nn.relu(Z7)\n",
    "    print(\"A7\")\n",
    "    print(np.shape(A7))\n",
    "    Z5 = tf.contrib.slim.conv2d_transpose(A7,3,[512,512],[2,2],activation_fn=tf.nn.relu)\n",
    "    A5 = tf.nn.relu(Z5)\n",
    "    print(\"A5\")\n",
    "    print(np.shape(A5))\n",
    "    return A5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(A5, Y):\n",
    "\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = A5, labels = Y))    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, learning_rate = 0.009,num_epochs = 100, minibatch_size = 24, print_cost = True):\n",
    "      \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep results consistent (tensorflow seed)\n",
    "    seed = 3      \n",
    "    m=1464                                    # to keep results consistent (numpy seed)\n",
    "#     (n_H0, n_W0, n_C0) = np.shape(X_train)          \n",
    "#     (n_H1,n_W1,n_C1) = np.shape(Y_train)   \n",
    "    n_H0 = 512\n",
    "    n_W0 = 512\n",
    "    n_C0 = 3\n",
    "    n_H1 = 512\n",
    "    n_W1 = 512\n",
    "    n_C1 = 3\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of the correct shape\n",
    "    X, Y = create_placeholders(n_H0, n_W0, n_C0, n_H1,n_W1,n_C1)\n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters()     \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    A5 = forward_propagation(X, parameters)    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    cost = compute_cost(A5, Y)    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost.\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)    \n",
    "    # Initialize all the variables globally\n",
    "    init = tf.global_variables_initializer()\n",
    "    seed = 0\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            minibatch_cost = 0.\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            # minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "            print(num_minibatches)\n",
    "            print(epoch)\n",
    "            for minibatch in range(num_minibatches):\n",
    "\n",
    "                # Select a minibatch\n",
    "                minibatch_X = X_train[(seed*minibatch_size):((seed*minibatch_size)+minibatch_size)]\n",
    "                minibatch_Y = Y_train[(seed*minibatch_size):((seed*minibatch_size)+minibatch_size)]\n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the optimizer and the cost, the feedict should contain a minibatch for (X,Y).\n",
    "                _ , temp_cost = sess.run([optimizer, cost], feed_dict={X:minibatch_X, Y:minibatch_Y})\n",
    "                \n",
    "                minibatch_cost += temp_cost / num_minibatches\n",
    "            \n",
    "            seed = seed + 1    \n",
    "\n",
    "            # Print the cost every epoch\n",
    "            #if print_cost == True and epoch % 5 == 0:\n",
    "            print (\"Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n",
    "            # if print_cost == True and epoch % 1 == 0:\n",
    "            costs.append(minibatch_cost)\n",
    "        \n",
    "        \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        predict_op = tf.argmax(A5, 1)\n",
    "        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "        \n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print(accuracy)\n",
    "        # train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n",
    "        # test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n",
    "        # print(\"Train Accuracy:\", train_accuracy)\n",
    "        # print(\"Test Accuracy:\", test_accuracy)\n",
    "                \n",
    "        return train_accuracy, test_accuracy, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,parameters = model(features,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
